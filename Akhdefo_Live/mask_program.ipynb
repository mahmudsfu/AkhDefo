{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask saved as mask.png\n",
      "Mask saved as mask.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize global variables\n",
    "drawing = False  # True if mouse is down, used to track drawing state\n",
    "points = []  # List to store points of the polygon\n",
    "\n",
    "# Mouse callback function to draw polygon and trigger mask creation\n",
    "def draw_polygon(event, x, y, flags, param):\n",
    "    global points, drawing\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        points.append((x, y))  # Add point on left mouse button down\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        # Finalize drawing on double click\n",
    "        drawing = False\n",
    "        if len(points) > 2:\n",
    "            mask = create_mask(frame.shape, points)  # Create mask based on polygon points\n",
    "            cv2.fillPoly(frame, [np.array(points, np.int32)], (0, 0, 0))  # Apply mask to the frame visually\n",
    "            save_mask(mask, 'mask.png')  # Save the created mask\n",
    "        points.clear()  # Clear the points after drawing the polygon\n",
    "\n",
    "# Function to create binary mask from polygon points\n",
    "def create_mask(shape, polygon_points):\n",
    "    \"\"\"\n",
    "    Creates a binary mask where the polygon area is 1 and the outside is 0.\n",
    "    :param shape: Tuple of the dimensions of the frame (height, width, channels).\n",
    "    :param polygon_points: List of points (x, y) that make up the polygon.\n",
    "    :return: Binary mask as a numpy array.\n",
    "    \"\"\"\n",
    "    mask = np.zeros(shape[:2], dtype=np.uint8)  # Initialize mask with zeros\n",
    "    cv2.fillPoly(mask, [np.array(polygon_points, np.int32)], 1)  # Fill polygon area in the mask with 1\n",
    "    return mask\n",
    "\n",
    "# Function to save the binary mask to a file\n",
    "def save_mask(mask, filename):\n",
    "    \"\"\"\n",
    "    Saves the binary mask to a file.\n",
    "    :param mask: Binary mask as a numpy array.\n",
    "    :param filename: Filename for the saved mask image.\n",
    "    \"\"\"\n",
    "    cv2.imwrite(filename, mask * 255)  # Convert binary mask (0,1) to image format (0,255) and save\n",
    "    print(f\"Mask saved as {filename}\")\n",
    "\n",
    "# Function to capture video, display it, and allow drawing of polygons\n",
    "def mask_video(video_path):\n",
    "    global frame  # To modify the frame within the callback\n",
    "    cap = cv2.VideoCapture(video_path)  # Capture video from the specified path\n",
    "    cv2.namedWindow('Video')\n",
    "    cv2.setMouseCallback('Video', draw_polygon)  # Set mouse callback for drawing\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()  # Read frames from the video\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        if len(points) > 1:\n",
    "            # Draw the current polygon being drawn\n",
    "            tmp_frame = frame.copy()\n",
    "            cv2.polylines(tmp_frame, [np.array(points, np.int32)], False, (0, 255, 0), 1)\n",
    "            cv2.imshow('Video', tmp_frame)\n",
    "        else:\n",
    "            cv2.imshow('Video', frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):  # Press 'q' to quit the application\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "# Example usage\n",
    "video_path = 'https://chiefcam.com/video/hls/live/1080p/index.m3u8'\n",
    "#'https://chiefcam.com/video/hls/live/1080p/index.m3u8'\n",
    "\n",
    "mask_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image in grayscale\n",
    "image = cv2.imread('mask.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if image is None:\n",
    "    print('Failed to load image')\n",
    "else:\n",
    "    # Threshold the image to make sure it's binary\n",
    "    _, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Assuming you want to work with the largest contour\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Create an empty mask for the distance transform\n",
    "        mask = np.zeros_like(image)\n",
    "        cv2.drawContours(mask, [largest_contour], -1, 255, -1)  # Draw filled contour\n",
    "        \n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "        \n",
    "        print(f\"x,y,w,h: {x,y, w, h}\")\n",
    "        \n",
    "        # Apply distance transform\n",
    "        dist_transform = cv2.distanceTransform(mask, cv2.DIST_L2, 5)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(dist_transform)\n",
    "        print( min_val, max_val, min_loc, (max_loc))\n",
    "        # The maximum location is the center of the circle\n",
    "        center = (max_loc)\n",
    "        radius = int(max_val)  # The maximum value is the radius of the circle\n",
    "        \n",
    "        # Define the cropping rectangle\n",
    "        radius = int(max_val)\n",
    "        top_left = (max(max_loc[0] - radius, 0), max(max_loc[1] - radius, 0))\n",
    "        bottom_right = (min(max_loc[0] + radius, mask.shape[1] - 1), min(max_loc[1] + radius, mask.shape[0] - 1))\n",
    "        \n",
    "        print(f'top_left:{top_left}, bottom_right: {bottom_right}')\n",
    "\n",
    "        # Draw the circle on the original image\n",
    "        output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)  # Convert to BGR to draw colored shapes\n",
    "        cv2.circle(output_image, center, radius, (0, 255, 0), 2)  # Draw the circle in green with thickness 2\n",
    "\n",
    "        # Optionally, show or save the result\n",
    "        cv2.imshow('Inscribed Circle', output_image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print('No contours found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , subprocess\n",
    "\n",
    "def set_video_bitrate(input_video_path, output_video_path, bitrate_kbps):\n",
    "    \"\"\"\n",
    "    Set the bitrate of a video using FFmpeg. If the output file already exists, a new file with a suffix is created instead.\n",
    "\n",
    "    Parameters:\n",
    "    - input_video_path: Path to the input video file.\n",
    "    - output_video_path: Path where the output video with the new bitrate will be saved.\n",
    "    - bitrate_kbps: Desired video bitrate in kbps.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the output file already exists\n",
    "        original_output_path = output_video_path\n",
    "        counter = 1\n",
    "        while os.path.exists(output_video_path):\n",
    "            # Split the output path into directory, base name, and extension\n",
    "            dir_name, base_name = os.path.split(original_output_path)\n",
    "            file_name, file_extension = os.path.splitext(base_name)\n",
    "            \n",
    "            # Append a suffix to make the file name unique\n",
    "            output_video_path = os.path.join(dir_name, f\"{file_name}_{counter}{file_extension}\")\n",
    "            counter += 1\n",
    "\n",
    "        # Build the FFmpeg command\n",
    "        command = [\n",
    "            'ffmpeg',\n",
    "            '-i', input_video_path,\n",
    "            '-b:v', f'{bitrate_kbps}k',\n",
    "            '-bufsize', f'{int(bitrate_kbps * 2)}k',  # Optional: Adjust buffer size\n",
    "            output_video_path\n",
    "        ]\n",
    "\n",
    "        # Execute the FFmpeg command\n",
    "        subprocess.run(command, check=True)\n",
    "\n",
    "        print(f\"Video with bitrate {bitrate_kbps} kbps saved as {output_video_path}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to set bitrate: {e}\")\n",
    "        \n",
    "        \n",
    "set_video_bitrate('./plots/GIFS/frame_2024-03-20_0_image.mp4', './plots/GIFS/converted/frame_2024-03-20_0_image.mp4', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Initialize the MOG2 background subtractor\n",
    "backSub = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n",
    "\n",
    "# Open the video file or capture device\n",
    "cap = cv2.VideoCapture('https://chiefcam.com/video/hls/live/1080p/index.m3u8')\n",
    "\n",
    "ret, frame1 = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to read the video stream\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    exit()\n",
    "\n",
    "prev_gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Initialize an empty frame for the running weighted average\n",
    "avg_frame = None\n",
    "alpha = 0.1  # Weight for the running average\n",
    "\n",
    "# Initialize variables for ORB feature tracking\n",
    "prev_keypoints, prev_descriptors = orb.detectAndCompute(prev_gray, None)\n",
    "\n",
    "# Load the uploaded mask and convert it to grayscale\n",
    "uploaded_mask = cv2.imread('mask.png', cv2.IMREAD_GRAYSCALE)\n",
    "if uploaded_mask is None:\n",
    "    print(\"Failed to load mask.png\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    exit()\n",
    "shifts_x = []\n",
    "shifts_y = []\n",
    "import matplotlib.pyplot as plt\n",
    "# Initialize plotting\n",
    "plt.ion()  # Turn on interactive mode for live updates\n",
    "fig, ax = plt.subplots()\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize uploaded mask to match frame size if necessary\n",
    "    if uploaded_mask.shape != frame1.shape[:2]:\n",
    "        uploaded_mask = cv2.resize(uploaded_mask, (frame1.shape[1], frame1.shape[0]))\n",
    "    gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Feature matching\n",
    "    keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(prev_descriptors, descriptors)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    if len(matches) > 10:  # Ensure we have enough matches to find a homography\n",
    "        src_pts = np.float32([prev_keypoints[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        if M is not None:\n",
    "            h, w = gray.shape\n",
    "            gray = cv2.warpPerspective(gray, M, (w, h))\n",
    "            \n",
    "            # Calculate and display the shift in x and y directions\n",
    "            dx, dy = M[0, 2], M[1, 2]\n",
    "            #print(f\"Shift in x: {dx:.2f}, Shift in y: {dy:.2f}\")\n",
    "            \n",
    "           \n",
    "            shifts_x.append(dx)\n",
    "            shifts_y.append(dy)\n",
    "\n",
    "        \n",
    "\n",
    "    # Update keypoints and descriptors for the next frame\n",
    "    prev_keypoints, prev_descriptors = keypoints, descriptors\n",
    "\n",
    "    # Apply MOG2 to get the foreground mask\n",
    "    fgMask = backSub.apply(gray)\n",
    "\n",
    "    # Initialize avg_frame if it has not been initialized\n",
    "    if avg_frame is None:\n",
    "        avg_frame = np.float32(gray)\n",
    "\n",
    "    # Calculate the weighted average\n",
    "    cv2.accumulateWeighted(gray, avg_frame, alpha)\n",
    "    avg_gray = cv2.convertScaleAbs(avg_frame)\n",
    "\n",
    "    # Thresholding the difference between the current frame and the running average\n",
    "    _, avg_mask = cv2.threshold(cv2.absdiff(gray, avg_gray), 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Combine MOG2 mask and weighted average mask to refine the foreground mask\n",
    "    combined_mask = cv2.bitwise_and(fgMask, avg_mask)\n",
    "    # Now combine the uploaded mask with the combined_mask from video processing\n",
    "    final_mask = cv2.bitwise_and(combined_mask, uploaded_mask)\n",
    "\n",
    "    # Calculate dense optical flow\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # Compute the magnitude and angle of the 2D vectors\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "    # Set the magnitude of optical flow to zero wherever the combined mask is zero\n",
    "    magnitude[final_mask == 0] = 0\n",
    "\n",
    "    # Visualization of the optical flow magnitude (optional)\n",
    "    norm_mag = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    cv2.imshow('Optical Flow Magnitude (Foreground)', norm_mag.astype(np.uint8))\n",
    "\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize plotting\n",
    "plt.ion()  # Turn on interactive mode for live updates\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Your existing video processing setup here\n",
    "# ...\n",
    "\n",
    "shifts_x = []\n",
    "shifts_y = []\n",
    "\n",
    "while True:\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Your existing video processing logic here\n",
    "    # ...\n",
    "\n",
    "    if M is not None:\n",
    "        # Extract shifts and append to lists for plotting\n",
    "        dx, dy = M[0, 2], M[1, 2]\n",
    "        shifts_x.append(dx)\n",
    "        shifts_y.append(dy)\n",
    "\n",
    "       \n",
    "        ax.clear()\n",
    "        ax.plot(shifts_x, label='Shift in X')\n",
    "        ax.plot(shifts_y, label='Shift in Y')\n",
    "        ax.legend()\n",
    "        plt.draw()\n",
    "        plt.pause(0.01)  # Pause to ensure the plot updates\n",
    "\n",
    "    # Your existing video processing logic here\n",
    "    # ...\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "plt.ioff()  # Turn off interactive mode\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "akhdefov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
